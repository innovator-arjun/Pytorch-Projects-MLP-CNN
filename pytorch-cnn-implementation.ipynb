{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-22T16:52:26.705909Z",
     "iopub.status.busy": "2021-01-22T16:52:26.701835Z",
     "iopub.status.idle": "2021-01-22T16:52:30.612230Z",
     "shell.execute_reply": "2021-01-22T16:52:30.612758Z"
    },
    "papermill": {
     "duration": 3.943192,
     "end_time": "2021-01-22T16:52:30.612936",
     "exception": false,
     "start_time": "2021-01-22T16:52:26.669744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # for plotting beautiful graphs\n",
    "\n",
    "# train test split from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import Torch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models,datasets\n",
    "# from torch.utils.data import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# What's in the current directory?\n",
    "import os\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T16:52:30.653886Z",
     "iopub.status.busy": "2021-01-22T16:52:30.653185Z",
     "iopub.status.idle": "2021-01-22T16:52:38.172569Z",
     "shell.execute_reply": "2021-01-22T16:52:38.171842Z"
    },
    "papermill": {
     "duration": 7.54441,
     "end_time": "2021-01-22T16:52:38.172690",
     "exception": false,
     "start_time": "2021-01-22T16:52:30.628280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    0.0\n",
       "2    1.0\n",
       "3    4.0\n",
       "4    0.0\n",
       "Name: label, dtype: float32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"../input/digit-recognizer/train.csv\", dtype=np.float32)\n",
    "final_test = pd.read_csv(\"../input/digit-recognizer/test.csv\", dtype=np.float32)\n",
    "sample_sub = pd.read_csv(\"../input/digit-recognizer/sample_submission.csv\")\n",
    "train.label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T16:52:38.209274Z",
     "iopub.status.busy": "2021-01-22T16:52:38.208558Z",
     "iopub.status.idle": "2021-01-22T16:52:38.219337Z",
     "shell.execute_reply": "2021-01-22T16:52:38.217615Z"
    },
    "papermill": {
     "duration": 0.032178,
     "end_time": "2021-01-22T16:52:38.219513",
     "exception": false,
     "start_time": "2021-01-22T16:52:38.187335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T16:52:38.302059Z",
     "iopub.status.busy": "2021-01-22T16:52:38.301167Z",
     "iopub.status.idle": "2021-01-22T16:52:38.598053Z",
     "shell.execute_reply": "2021-01-22T16:52:38.597189Z"
    },
    "papermill": {
     "duration": 0.357371,
     "end_time": "2021-01-22T16:52:38.598197",
     "exception": false,
     "start_time": "2021-01-22T16:52:38.240826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seperate the features and labels\n",
    "targets_np = train.label.values\n",
    "features_np = train.loc[:, train.columns != 'label'].values/255\n",
    "\n",
    "# Split into training and test set\n",
    "features_train, features_test, target_train, target_test = train_test_split(features_np, targets_np, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T16:52:38.649549Z",
     "iopub.status.busy": "2021-01-22T16:52:38.648201Z",
     "iopub.status.idle": "2021-01-22T16:52:38.656521Z",
     "shell.execute_reply": "2021-01-22T16:52:38.655399Z"
    },
    "papermill": {
     "duration": 0.037737,
     "end_time": "2021-01-22T16:52:38.656665",
     "exception": false,
     "start_time": "2021-01-22T16:52:38.618928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# If a GPU is available, use it\n",
    "# Pytorch uses an elegant way to keep the code device agnostic\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    use_cuda = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    use_cuda = False\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T16:52:38.727613Z",
     "iopub.status.busy": "2021-01-22T16:52:38.723669Z",
     "iopub.status.idle": "2021-01-22T16:52:38.758913Z",
     "shell.execute_reply": "2021-01-22T16:52:38.758317Z"
    },
    "papermill": {
     "duration": 0.078853,
     "end_time": "2021-01-22T16:52:38.759034",
     "exception": false,
     "start_time": "2021-01-22T16:52:38.680181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
    "featuresTrain = torch.from_numpy(features_train)\n",
    "targetsTrain = torch.from_numpy(target_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set.\n",
    "featuresTest = torch.from_numpy(features_test)\n",
    "targetsTest = torch.from_numpy(target_test).type(torch.LongTensor) # data type is long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T16:52:38.797227Z",
     "iopub.status.busy": "2021-01-22T16:52:38.796568Z",
     "iopub.status.idle": "2021-01-22T16:52:38.802029Z",
     "shell.execute_reply": "2021-01-22T16:52:38.801300Z"
    },
    "papermill": {
     "duration": 0.027792,
     "end_time": "2021-01-22T16:52:38.802144",
     "exception": false,
     "start_time": "2021-01-22T16:52:38.774352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
    "test = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T16:52:38.848044Z",
     "iopub.status.busy": "2021-01-22T16:52:38.846093Z",
     "iopub.status.idle": "2021-01-22T16:52:39.578040Z",
     "shell.execute_reply": "2021-01-22T16:52:39.576333Z"
    },
    "papermill": {
     "duration": 0.760194,
     "end_time": "2021-01-22T16:52:39.578232",
     "exception": false,
     "start_time": "2021-01-22T16:52:38.818038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256, 784])\n",
      "torch.Size([64, 784])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (inputs, target) in enumerate(train_loader):\n",
    "    print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T16:52:39.646337Z",
     "iopub.status.busy": "2021-01-22T16:52:39.635422Z",
     "iopub.status.idle": "2021-01-22T16:52:39.656672Z",
     "shell.execute_reply": "2021-01-22T16:52:39.655923Z"
    },
    "papermill": {
     "duration": 0.057549,
     "end_time": "2021-01-22T16:52:39.656842",
     "exception": false,
     "start_time": "2021-01-22T16:52:39.599293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # conv block 1\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # conv block 2\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Linear(64*7*7, 512)\n",
    "        self.bn5 = nn.BatchNorm1d(512)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is [batch_size, channels, heigth, width] = [bs, 1, 28, 28]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2) # x is [bs, 32, 14, 14]\n",
    "        \n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.max_pool2d(x, 2) # x is [bs, 64, 7, 7]\n",
    "        \n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        \n",
    "        x = F.relu(self.bn5(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T16:52:39.716104Z",
     "iopub.status.busy": "2021-01-22T16:52:39.715181Z",
     "iopub.status.idle": "2021-01-22T16:52:39.722433Z",
     "shell.execute_reply": "2021-01-22T16:52:39.721836Z"
    },
    "papermill": {
     "duration": 0.041102,
     "end_time": "2021-01-22T16:52:39.722560",
     "exception": false,
     "start_time": "2021-01-22T16:52:39.681458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Surrogate loss used for training\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "test_loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "# spot to save your learning curves, and potentially checkpoint your models\n",
    "savedir = 'results'\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T16:52:39.773140Z",
     "iopub.status.busy": "2021-01-22T16:52:39.772448Z",
     "iopub.status.idle": "2021-01-22T16:52:39.779860Z",
     "shell.execute_reply": "2021-01-22T16:52:39.778778Z"
    },
    "papermill": {
     "duration": 0.040168,
     "end_time": "2021-01-22T16:52:39.779984",
     "exception": false,
     "start_time": "2021-01-22T16:52:39.739816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch ):\n",
    "    \"\"\"Perform one epoch of training.\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (inputs, target) in enumerate(train_loader):\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "        \n",
    "        # Let them code what's here\n",
    "        optimizer.zero_grad()\n",
    "        inputs = Variable(inputs.view(-1,1,28,28))\n",
    "        output = model(inputs)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ###\n",
    "        \n",
    "        #print('Train Epoch:{}'.format(epoch))\n",
    "        #if batch_idx % 10 == 0:\n",
    "            #print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            #    epoch, batch_idx * len(inputs), len(train_loader) *len(inputs) ,\n",
    "            #    100. * batch_idx / len(train_loader), loss.item()))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T16:52:39.834083Z",
     "iopub.status.busy": "2021-01-22T16:52:39.825193Z",
     "iopub.status.idle": "2021-01-22T16:52:39.839809Z",
     "shell.execute_reply": "2021-01-22T16:52:39.839084Z"
    },
    "papermill": {
     "duration": 0.042833,
     "end_time": "2021-01-22T16:52:39.839925",
     "exception": false,
     "start_time": "2021-01-22T16:52:39.797092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader,epoch):\n",
    "    \"\"\"Evaluate the model by doing one pass over a dataset\"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_size = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, target in test_loader:\n",
    "            inputs, target = inputs.to(device), target.to(device)\n",
    "            \n",
    "            # TODO: code the evaluation loop\n",
    "            inputs = Variable(inputs.view(-1,1,28,28))\n",
    "            output = model(inputs)\n",
    "            test_size += len(inputs)\n",
    "            test_loss += test_loss_fn(output, target).item() # sum up batch loss\n",
    "            # output = batch size * n_classes\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            # pred = output.max(1, keepdim=True)\n",
    "            # pred = pred[1] # get the index of the max log-probability\n",
    "\n",
    "            # correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            # #\n",
    "    test_loss /= test_size\n",
    "    accuracy = correct / test_size\n",
    "    print('Test Epoch:{}'.format(epoch))\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, test_size,\n",
    "        100. * accuracy))\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T16:52:39.894743Z",
     "iopub.status.busy": "2021-01-22T16:52:39.885340Z",
     "iopub.status.idle": "2021-01-22T18:06:33.863265Z",
     "shell.execute_reply": "2021-01-22T18:06:33.864988Z"
    },
    "papermill": {
     "duration": 4434.008219,
     "end_time": "2021-01-22T18:06:33.865359",
     "exception": false,
     "start_time": "2021-01-22T16:52:39.857140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:1\n",
      "\n",
      "Test set: Average loss: 0.0499, Accuracy: 8278/8400 (98.55%)\n",
      "\n",
      "Test Epoch:2\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 8329/8400 (99.15%)\n",
      "\n",
      "Test Epoch:3\n",
      "\n",
      "Test set: Average loss: 0.0320, Accuracy: 8317/8400 (99.01%)\n",
      "\n",
      "Test Epoch:4\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 8320/8400 (99.05%)\n",
      "\n",
      "Test Epoch:5\n",
      "\n",
      "Test set: Average loss: 0.0330, Accuracy: 8310/8400 (98.93%)\n",
      "\n",
      "Test Epoch:6\n",
      "\n",
      "Test set: Average loss: 0.0286, Accuracy: 8319/8400 (99.04%)\n",
      "\n",
      "Test Epoch:7\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 8325/8400 (99.11%)\n",
      "\n",
      "Test Epoch:8\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 8331/8400 (99.18%)\n",
      "\n",
      "Test Epoch:9\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 8334/8400 (99.21%)\n",
      "\n",
      "Test Epoch:10\n",
      "\n",
      "Test set: Average loss: 0.0288, Accuracy: 8329/8400 (99.15%)\n",
      "\n",
      "Test Epoch:11\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 8328/8400 (99.14%)\n",
      "\n",
      "Test Epoch:12\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 8340/8400 (99.29%)\n",
      "\n",
      "Test Epoch:13\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 8348/8400 (99.38%)\n",
      "\n",
      "Test Epoch:14\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 8346/8400 (99.36%)\n",
      "\n",
      "Test Epoch:15\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 8337/8400 (99.25%)\n",
      "\n",
      "Test Epoch:16\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 8333/8400 (99.20%)\n",
      "\n",
      "Test Epoch:17\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 8349/8400 (99.39%)\n",
      "\n",
      "Test Epoch:18\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 8348/8400 (99.38%)\n",
      "\n",
      "Test Epoch:19\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 8360/8400 (99.52%)\n",
      "\n",
      "Test Epoch:20\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 8358/8400 (99.50%)\n",
      "\n",
      "Test Epoch:21\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 8362/8400 (99.55%)\n",
      "\n",
      "Test Epoch:22\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 8362/8400 (99.55%)\n",
      "\n",
      "Test Epoch:23\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 8365/8400 (99.58%)\n",
      "\n",
      "Test Epoch:24\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 8363/8400 (99.56%)\n",
      "\n",
      "Test Epoch:25\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 8364/8400 (99.57%)\n",
      "\n",
      "Test Epoch:26\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 8363/8400 (99.56%)\n",
      "\n",
      "Test Epoch:27\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 8361/8400 (99.54%)\n",
      "\n",
      "Test Epoch:28\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 8363/8400 (99.56%)\n",
      "\n",
      "Test Epoch:29\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 8364/8400 (99.57%)\n",
      "\n",
      "Test Epoch:30\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 8363/8400 (99.56%)\n",
      "\n",
      "Test Epoch:31\n",
      "\n",
      "Test set: Average loss: 0.0165, Accuracy: 8365/8400 (99.58%)\n",
      "\n",
      "Test Epoch:32\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 8364/8400 (99.57%)\n",
      "\n",
      "Test Epoch:33\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 8362/8400 (99.55%)\n",
      "\n",
      "Test Epoch:34\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 8367/8400 (99.61%)\n",
      "\n",
      "Test Epoch:35\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 8366/8400 (99.60%)\n",
      "\n",
      "Test Epoch:36\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 8363/8400 (99.56%)\n",
      "\n",
      "Test Epoch:37\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 8364/8400 (99.57%)\n",
      "\n",
      "Test Epoch:38\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 8366/8400 (99.60%)\n",
      "\n",
      "Test Epoch:39\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 8364/8400 (99.57%)\n",
      "\n",
      "Test Epoch:40\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 8366/8400 (99.60%)\n",
      "\n",
      "Test Epoch:41\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 8366/8400 (99.60%)\n",
      "\n",
      "Test Epoch:42\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 8362/8400 (99.55%)\n",
      "\n",
      "Test Epoch:43\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 8363/8400 (99.56%)\n",
      "\n",
      "Test Epoch:44\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 8363/8400 (99.56%)\n",
      "\n",
      "Test Epoch:45\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 8364/8400 (99.57%)\n",
      "\n",
      "Test Epoch:46\n",
      "\n",
      "Test set: Average loss: 0.1020, Accuracy: 8205/8400 (97.68%)\n",
      "\n",
      "Test Epoch:47\n",
      "\n",
      "Test set: Average loss: 0.0292, Accuracy: 8318/8400 (99.02%)\n",
      "\n",
      "Test Epoch:48\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 8342/8400 (99.31%)\n",
      "\n",
      "Test Epoch:49\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 8353/8400 (99.44%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Classifier().to(device)\n",
    "\n",
    "#lr = 0.0005\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "results = {'name':'basic', 'loss': [], 'accuracy':[]}\n",
    "savefile = os.path.join(savedir, results['name']+'.pkl' )\n",
    "\n",
    "for epoch in range(1, 50):\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    loss, acc = test(model, test_loader, epoch)\n",
    "    \n",
    "    # save results every epoch\n",
    "    results['loss'].append(loss)\n",
    "    results['accuracy'].append(acc)\n",
    "    with open(savefile, 'wb') as fout:\n",
    "        pickle.dump(results, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T18:06:34.000333Z",
     "iopub.status.busy": "2021-01-22T18:06:33.997130Z",
     "iopub.status.idle": "2021-01-22T18:06:34.110343Z",
     "shell.execute_reply": "2021-01-22T18:06:34.111147Z"
    },
    "papermill": {
     "duration": 0.189888,
     "end_time": "2021-01-22T18:06:34.111437",
     "exception": false,
     "start_time": "2021-01-22T18:06:33.921549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_test_np = final_test.values/255\n",
    "test_tn = torch.from_numpy(final_test_np)\n",
    "fake_labels = np.zeros(final_test_np.shape)\n",
    "fake_labels = torch.from_numpy(fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T18:06:34.192028Z",
     "iopub.status.busy": "2021-01-22T18:06:34.191233Z",
     "iopub.status.idle": "2021-01-22T18:06:34.196637Z",
     "shell.execute_reply": "2021-01-22T18:06:34.195750Z"
    },
    "papermill": {
     "duration": 0.047508,
     "end_time": "2021-01-22T18:06:34.196767",
     "exception": false,
     "start_time": "2021-01-22T18:06:34.149259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_tn_data = torch.utils.data.TensorDataset(test_tn, fake_labels)\n",
    "submission_loader = torch.utils.data.DataLoader(submission_tn_data, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T18:06:34.280673Z",
     "iopub.status.busy": "2021-01-22T18:06:34.279710Z",
     "iopub.status.idle": "2021-01-22T18:06:59.758323Z",
     "shell.execute_reply": "2021-01-22T18:06:59.756816Z"
    },
    "papermill": {
     "duration": 25.525717,
     "end_time": "2021-01-22T18:06:59.758512",
     "exception": false,
     "start_time": "2021-01-22T18:06:34.232795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "with torch.no_grad():\n",
    "    for inputs, target in submission_loader:\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "        inputs = Variable(inputs.view(-1,1,28,28))  \n",
    "        #inputs = torch.unsqueeze(inputs, 0)\n",
    "        # TODO: code the evaluation loop\n",
    "        output = model(inputs)\n",
    "        pred = output.argmax(dim=1)\n",
    "        for i in range(len(pred)):\n",
    "            outputs.append(pred[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T18:06:59.862615Z",
     "iopub.status.busy": "2021-01-22T18:06:59.858228Z",
     "iopub.status.idle": "2021-01-22T18:06:59.920864Z",
     "shell.execute_reply": "2021-01-22T18:06:59.920055Z"
    },
    "papermill": {
     "duration": 0.108859,
     "end_time": "2021-01-22T18:06:59.921018",
     "exception": false,
     "start_time": "2021-01-22T18:06:59.812159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub =  open('mnist_cnn_sub2.csv','w+')\n",
    "sub.write('ImageId,Label\\n')\n",
    "for index, prediction in enumerate(outputs):\n",
    "    sub.write(str(index+1) + ',' + str(prediction) + '\\n')\n",
    "sub.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.053432,
     "end_time": "2021-01-22T18:07:00.027150",
     "exception": false,
     "start_time": "2021-01-22T18:06:59.973718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 4480.817587,
   "end_time": "2021-01-22T18:07:00.192289",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-22T16:52:19.374702",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
